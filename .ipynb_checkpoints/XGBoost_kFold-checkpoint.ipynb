{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 11)\n",
    "pd.set_option(\"display.max_columns\", 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 関数：ジニ係数\n",
    "# from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み・編集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "train = pd.read_csv('01.data/train.csv')\n",
    "test = pd.read_csv('01.data/test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特徴量と目的変数を分離\n",
    "features = train.drop(['id','target'], axis=1).values\n",
    "targets = train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
       "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
       "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#除外する変数を設定\n",
    "# 目的変数との相関がほぼゼロのため\n",
    "unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "unwanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 利用しない変数を除外\n",
    "train = train.drop(unwanted, axis=1)  \n",
    "test = test.drop(unwanted, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop(['id', 'target'], axis=1).values # 説明変数(idとかtargetを除外)\n",
    "y = train.target.values # 正解データ\n",
    "test_id = test.id.values\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission用データフレーム\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Foldを実装してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KFoldの設定\n",
    "kfold = 2\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost \n",
    "# More parameters has to be tuned\n",
    "# http://puyokw.hatenablog.com/entry/2015/04/11/040941\n",
    "params = {\n",
    "    # ブースター変数\n",
    "    'min_child_weight' : 10.0, # 子ノードにおける最小の重み　葉ノードの重みの合計がmin_child_weight未満で分割しない\n",
    "    'max_depth' : 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700,\n",
    "    # タスク変数\n",
    "    'objective': 'binary:logistic'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/2]\n",
      "[0]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.000652\tvalid-gini:0.004843\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 70 rounds.\n",
      "[100]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.336714\tvalid-gini:0.264463\n",
      "[200]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.384257\tvalid-gini:0.274752\n",
      "[300]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.430691\tvalid-gini:0.279561\n",
      "Stopping. Best iteration:\n",
      "[314]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.436123\tvalid-gini:0.279807\n",
      "\n",
      "[Fold 1/2 Prediciton:]\n",
      "[Fold 2/2]\n",
      "[0]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.004696\tvalid-gini:0.000795\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 70 rounds.\n",
      "[100]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.341451\tvalid-gini:0.262066\n",
      "[200]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.389597\tvalid-gini:0.269117\n",
      "[300]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.437675\tvalid-gini:0.273231\n",
      "[400]\ttrain-error:0.036431\tvalid-error:0.036448\ttrain-gini:0.472215\tvalid-gini:0.273515\n",
      "Stopping. Best iteration:\n",
      "[356]\ttrain-error:0.036434\tvalid-error:0.036448\ttrain-gini:0.45827\tvalid-gini:0.274122\n",
      "\n",
      "[Fold 2/2 Prediciton:]\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    \n",
    "    # Convert our data into XGBoost format\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(test.values)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    # Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n",
    "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "    mdl = xgb.train(params, \n",
    "                    d_train, \n",
    "                    1600, \n",
    "                    watchlist, \n",
    "                    early_stopping_rounds=70,\n",
    "                    feval=gini_xgb,\n",
    "                    maximize=True,\n",
    "                    verbose_eval=100)\n",
    "\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test)\n",
    "    sub['target'] += p_test/kfold\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('02.output/StratifiedKFold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Searchを実装してみたいがよくわからない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert our data into XGBoost format\n",
    "d_train = xgb.DMatrix(X_train, y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "d_test = xgb.DMatrix(test.values)\n",
    "#watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.004696\tvalid-gini:0.000795\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 70 rounds.\n",
      "[100]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.341451\tvalid-gini:0.262066\n",
      "[200]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.389597\tvalid-gini:0.269117\n",
      "[300]\ttrain-error:0.036448\tvalid-error:0.036448\ttrain-gini:0.437675\tvalid-gini:0.273231\n",
      "[400]\ttrain-error:0.036431\tvalid-error:0.036448\ttrain-gini:0.472215\tvalid-gini:0.273515\n",
      "Stopping. Best iteration:\n",
      "[356]\ttrain-error:0.036434\tvalid-error:0.036448\ttrain-gini:0.45827\tvalid-gini:0.274122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n",
    "# and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "mdl = xgb.train(params, \n",
    "                d_train, \n",
    "                1600, # num_boost_round \n",
    "                watchlist, \n",
    "                \n",
    "                early_stopping_rounds=70,\n",
    "                feval=gini_xgb, # 評価関数：in case using custom evaluation function\n",
    "                maximize=True, # Whether to maximize feval.\n",
    "                verbose_eval=100 # Requires at least one item in evals.\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# クロスバリデーションをしていると思っているが、よくわからない\n",
    "cv2 = xgb.cv(params,\n",
    "             d_train,\n",
    "             num_boost_round=300,\n",
    "             nfold=3,\n",
    "             stratified=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      "0           0.036448        0.000005          0.036448         0.000002\n",
      "1           0.036448        0.000005          0.036448         0.000002\n",
      "2           0.036448        0.000005          0.036448         0.000002\n",
      "3           0.036448        0.000005          0.036448         0.000002\n",
      "4           0.036448        0.000005          0.036448         0.000002\n",
      "..               ...             ...               ...              ...\n",
      "295         0.036448        0.000005          0.036448         0.000002\n",
      "296         0.036448        0.000005          0.036448         0.000002\n",
      "297         0.036448        0.000005          0.036448         0.000002\n",
      "298         0.036448        0.000005          0.036448         0.000002\n",
      "299         0.036448        0.000005          0.036448         0.000002\n",
      "\n",
      "[300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_range = [1, 5, 10, 20, 50 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'min_child_weight' : param_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=mdl,\n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <xgboost.core.Booster object at 0x1136b9d68> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5dcc8efd7c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/opt/pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0;32m--> 250\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <xgboost.core.Booster object at 0x1136b9d68> was passed"
     ]
    }
   ],
   "source": [
    "gs_fit = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
